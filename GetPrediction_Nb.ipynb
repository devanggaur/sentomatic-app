{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64cacb2",
   "metadata": {},
   "source": [
    "## Function to load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251d9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "\n",
    "    # loading json and creating model\n",
    "    from keras.models import model_from_json\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    # evaluate loaded model on test data\n",
    "    # loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    loaded_model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "    # print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d59a8",
   "metadata": {},
   "source": [
    "## Running model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103572aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2bb2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data, sampling_rate = librosa.load('output_m_happy.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc6f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(file_received):\n",
    "\n",
    "    # loading json and creating model\n",
    "    import librosa\n",
    "    import librosa.display\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import tensorflow as tf\n",
    "    from matplotlib.pyplot import specgram\n",
    "    import keras\n",
    "    from keras.preprocessing import sequence\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Embedding\n",
    "    from keras.layers import LSTM\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    # from keras.utils import to_categorical\n",
    "    from keras.layers import Input, Flatten, Dropout, Activation\n",
    "    from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "    from keras.models import Model\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from keras.models import model_from_json\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    data, sampling_rate = librosa.load('output_m_happy.wav')\n",
    "\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import librosa\n",
    "    import glob \n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    librosa.display.waveplot(data, sr=sampling_rate)\n",
    "    \n",
    "    livedf= pd.DataFrame(columns=['feature'])\n",
    "    \n",
    "    X, sample_rate = librosa.load(file_received, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "    print(\"Happy file = \", X)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "    featurelive = mfccs\n",
    "    livedf2 = featurelive\n",
    "    \n",
    "    livedf2= pd.DataFrame(data=livedf2)\n",
    "    livedf2 = livedf2.stack().to_frame().T\n",
    "    livedf2\n",
    "\n",
    "    twodim= np.expand_dims(livedf2, axis=2)\n",
    "    \n",
    "    loaded_model = load_model()\n",
    "\n",
    "    livepreds = loaded_model.predict(twodim, \n",
    "                             batch_size=32, \n",
    "                             verbose=1)\n",
    "    livepreds\n",
    "    livepreds1=livepreds.argmax(axis=1)\n",
    "    livepreds1\n",
    "\n",
    "    liveabc = livepreds1.astype(int).flatten()\n",
    "    print(liveabc)\n",
    "    \n",
    "    return liveabc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6ad81",
   "metadata": {},
   "source": [
    "## Label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a805ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_response(index):\n",
    "    response = \"\"\n",
    "    if index==0:\n",
    "        response = 'female_angry'\n",
    "    elif index==1:\n",
    "        response = 'female_calm'\n",
    "    elif index==2:\n",
    "        response = 'female_fearful'\n",
    "    elif index==3:\n",
    "        response = 'female_happy'\n",
    "    elif index==4:\n",
    "        response = 'female_sad'\n",
    "    elif index==5:\n",
    "        response = 'male_angry'\n",
    "    elif index==6:\n",
    "        response = 'male_calm'\n",
    "    elif index==7:\n",
    "        response = 'male_fearful'\n",
    "    elif index==8:\n",
    "        response = 'male_happy'\n",
    "    elif index==9:\n",
    "        response = 'male_sad'\n",
    "    else:\n",
    "        response = \"sentiment not recognized!\"\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7debc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_EXTENSIONS = set(['wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c7f26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_file(filename):\n",
    "\treturn '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd978e93",
   "metadata": {},
   "source": [
    "## Creating REST API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26109a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy file =  [0. 0. 0. ... 0. 0. 0.]\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 286ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2021 20:14:04] \"\u001b[37mPOST /api/v1/resources/sentiments/all/ HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "8\n",
      "male_happy\n",
      "{'predictedVoice': 'male_happy'}\n",
      "Happy file =  [0. 0. 0. ... 0. 0. 0.]\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2021 20:20:10] \"\u001b[37mPOST /api/v1/resources/sentiments/all/ HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "8\n",
      "male_happy\n",
      "{'predictedVoice': 'male_happy'}\n",
      "Happy file =  [0. 0. 0. ... 0. 0. 0.]\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Nov/2021 20:23:37] \"\u001b[37mPOST /api/v1/resources/sentiments/all/ HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "8\n",
      "male_happy\n",
      "{'predictedVoice': 'male_happy'}\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "from flask import request, jsonify\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "@app.errorhandler(404)\n",
    "def page_not_found(e):\n",
    "    return \"<h1>404</h1><p>The resource could not be found.</p>\", 404\n",
    "\n",
    "# A route to return sentiment for the input file/text from the user.\n",
    "@app.route('/api/v1/resources/sentiments/all/', methods=['POST'])\n",
    "def get_sentiment():\n",
    "    file_received = request.files['testfile']\n",
    "    response = {\n",
    "        \"predictedVoice\": \"\"\n",
    "    }\n",
    "    index = get_prediction(file_received)\n",
    "    print(index)\n",
    "    response[\"predictedVoice\"] = encode_response(index)\n",
    "    print(response)\n",
    "    return jsonify(response)\n",
    "app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
